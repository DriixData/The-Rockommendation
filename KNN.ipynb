{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FONCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# modèle\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bool_colonne(df, df_recherche2, colonne):\n",
    "\n",
    "    df[colonne] = df[colonne].astype(str)\n",
    "    df[colonne] = df[colonne].apply(lambda x : x.replace('[', '').replace(']', '').replace(\"'\", '').replace(\", \", \",\"))\n",
    "    df[colonne] = df[colonne].apply(lambda x : x.split(','))\n",
    "\n",
    "    df_recherche2[colonne] = df_recherche2[colonne].astype(str)\n",
    "    df_recherche2[colonne] = df_recherche2[colonne].apply(lambda x : x.replace('[', '').replace(']', '').replace(\"'\", '').replace(\", \", \",\"))\n",
    "    df_recherche2[colonne] = df_recherche2[colonne].apply(lambda x : x.split(','))\n",
    "\n",
    "    tous_les_genres = []\n",
    "\n",
    "    for element in df_recherche2[colonne].iloc[0] :\n",
    "        if colonne == 'acteur_out_KNN':\n",
    "            if element in liste_acteurs_recurrents:\n",
    "                tous_les_genres.append(element)\n",
    "                tous_les_genres = list(set(tous_les_genres))\n",
    "        elif colonne == 'realisateurs_out_KNN':\n",
    "            if element in liste_realisateurs_recurrents:\n",
    "                tous_les_genres.append(element)\n",
    "                tous_les_genres = list(set(tous_les_genres))\n",
    "        elif colonne == 'production_companies_name_out_KNN':\n",
    "            if element in liste_production_recurrents:\n",
    "                tous_les_genres.append(element)\n",
    "        else:\n",
    "            tous_les_genres.append(element)  \n",
    "\n",
    "    for element2 in tous_les_genres:\n",
    "        df[f'{colonne[0:-8]}_{element2}'] = df[f'{colonne}'].apply(lambda x: element2 in x)\n",
    "\n",
    "    return df, tous_les_genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FONCTION 1\n",
    "\n",
    "def encodage_X(X, type, poids):\n",
    "  from sklearn.preprocessing import StandardScaler\n",
    "  index = X.index\n",
    "  X_num = X.select_dtypes('number')\n",
    "\n",
    "  if type == 'standard':\n",
    "      from sklearn.preprocessing import StandardScaler\n",
    "      SN = StandardScaler()\n",
    "      X_num_SN = pd.DataFrame(SN.fit_transform(X_num), columns=X_num.columns)\n",
    "\n",
    "  else:\n",
    "      from sklearn.preprocessing import MinMaxScaler\n",
    "      SN = MinMaxScaler()\n",
    "      X_num_SN = pd.DataFrame(SN.fit_transform(X_num), columns=X_num.columns)\n",
    "\n",
    "  X_num_SN = X_num_SN.mul(poids, axis = 1)\n",
    "  X_encoded = X_num_SN\n",
    "\n",
    "  X_encoded = X_encoded.dropna()\n",
    "\n",
    "  return X_encoded, SN\n",
    "\n",
    "# FONCTION 2\n",
    "\n",
    "def evaluate_k(X_encoded, k_range):\n",
    "    \"\"\"\n",
    "    Évalue différentes valeurs de k en utilisant la somme des distances aux voisins\n",
    "    et le score de silhouette comme métriques.\n",
    "\n",
    "    Args:\n",
    "        X_encoded (DataFrame): Données normalisées\n",
    "        k_range (range): Plage de valeurs de k à tester\n",
    "\n",
    "    Returns:\n",
    "        tuple: (distances moyennes, scores de silhouette)\n",
    "    \"\"\"\n",
    "    from sklearn.metrics import silhouette_score\n",
    "    from sklearn.cluster import KMeans\n",
    "\n",
    "    avg_distances = []\n",
    "    silhouette_scores = []\n",
    "\n",
    "    for k in k_range:\n",
    "        # Calcul des distances moyennes pour chaque k\n",
    "        from sklearn.neighbors import NearestNeighbors\n",
    "        model = NearestNeighbors(n_neighbors=k)\n",
    "        model.fit(X_encoded)\n",
    "        distances, _ = model.kneighbors(X_encoded)\n",
    "        avg_distances.append(np.mean(distances))\n",
    "\n",
    "        # Calcul du score de silhouette\n",
    "        # Nous utilisons KMeans pour créer des clusters et évaluer la qualité\n",
    "        kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "        clusters = kmeans.fit_predict(X_encoded)\n",
    "        if k > 1:  # Le score de silhouette nécessite au moins 2 clusters\n",
    "            silhouette_scores.append(silhouette_score(X_encoded, clusters))\n",
    "        else:\n",
    "            silhouette_scores.append(0)\n",
    "\n",
    "    return avg_distances, silhouette_scores\n",
    "\n",
    "# FONCTION 3\n",
    "\n",
    "def encodage_predict(df_a_predire, SN, poids, X_encoded):\n",
    "  X_num = df_a_predire.select_dtypes('number')\n",
    "\n",
    "  X_num_SN = pd.DataFrame(SN.transform(X_num), columns=X_num.columns).reset_index(drop=True)\n",
    "  X_num_SN = X_num_SN.mul(poids, axis = 1)\n",
    "  \n",
    "  X_encoded_predire = X_num_SN\n",
    "\n",
    "  df_predict = X_encoded_predire\n",
    "\n",
    "  # DataFrame vide qui a les mêmes colonnes que X_encoded\n",
    "  df_final = pd.DataFrame(columns=X_encoded.columns)\n",
    "\n",
    "  # On veut que le DataFrame ait le même nombre de lignes que df_predict\n",
    "  df_final = df_final.reindex(index=df_predict.index)\n",
    "  # On met tous les NaN à False\n",
    "  df_final = df_final.fillna(False)\n",
    "\n",
    "  # On parcourt chaque colonne de df_predict\n",
    "  # Si la colonne est présente dans X_encoded alors on la garde\n",
    "  # Sinon, on la met à False\n",
    "  for column in df_predict.columns:\n",
    "    if column in X_encoded.columns:\n",
    "      df_final[column] = df_predict[column]\n",
    "\n",
    "  return df_final\n",
    "\n",
    "# FONCTION 4\n",
    "\n",
    "def pokemons_similaires(X, film_id, model, SN, poids, X_encoded, df):\n",
    "\n",
    "  # Vérifier si le Pokémon existe dans le dataset\n",
    "  if film_id not in X['film_id_out_KNN'].values:\n",
    "      return f\"Le Pokémon {film_id} n'est pas dans le dataset.\"\n",
    "\n",
    "  # Récupérer les caractéristiques du Pokémon\n",
    "  pokemon = X[X['film_id_out_KNN'] == film_id]\n",
    "\n",
    "  # Je recopie ce qu'on a fait avant:\n",
    "  caract_pokemon = X[X['film_id_out_KNN'] == film_id]\n",
    "\n",
    "  caract_pokemon_encoded = encodage_predict(caract_pokemon, SN, poids, X_encoded)\n",
    "\n",
    "  distances, indices = model.kneighbors(caract_pokemon_encoded)\n",
    "\n",
    "  return df.iloc[indices[0]].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2b/18xblx_n4lv24wz932vjckrm0000gp/T/ipykernel_25699/3122574319.py:2: DtypeWarning: Columns (19) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('BD/P2_G5_films.csv.gz', compression = 'gzip')\n"
     ]
    }
   ],
   "source": [
    "# df = pd.read_csv('BD/P2_G5_films.csv.gz', compression = 'gzip', na_values = ['\\\\N'])\n",
    "df = pd.read_csv('BD/P2_G5_films.csv.gz', compression = 'gzip')\n",
    "df = df.fillna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_acteurs = df.copy()\n",
    "df_realisateurs = df.copy()\n",
    "df_production = df.copy()\n",
    "df_acteurs_recurrents = df.copy()\n",
    "df_realisateurs_recurrents = df.copy()\n",
    "df_production_reccurent = df.copy()\n",
    "df_recherche = df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ACTEURS, REALISATEURS ET PRODUCTION RECURRENTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "liste_acteurs_recurrents = []\n",
    "for element in df.columns:\n",
    "    if 'acteur' in element:\n",
    "        liste_acteurs_recurrents.append(element[7:])\n",
    "        \n",
    "liste_realisateurs_recurrents = []\n",
    "for element in df.columns:\n",
    "    if 'realisateur' in element:\n",
    "        liste_realisateurs_recurrents.append(element[13:])\n",
    "\n",
    "liste_production_companies_name_recurrents = []\n",
    "for element in df.columns:\n",
    "    if 'production_companies_name' in element:\n",
    "        liste_production_companies_name_recurrents.append(element[26:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHOIX DES CARACTERISTIQUES\n",
    "\n",
    "caracteristiques = []\n",
    "\n",
    "for element in df.columns:\n",
    "    if 'out_KNN' not in element:\n",
    "        caracteristiques.append(element)\n",
    "\n",
    "caracteristiques_num = []\n",
    "\n",
    "for element in df.select_dtypes(include = 'number').columns:\n",
    "    if 'out_KNN' not in element:\n",
    "        caracteristiques_num.append(element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# METTRE UNIQUEMENT POUR LES COLONNES NUMERIQUES\n",
    "\n",
    "poids_list = pd.DataFrame(columns = caracteristiques_num, index = ['poids'])\n",
    "\n",
    "colonne_cle = 10\n",
    "tres_important = 8\n",
    "important = 4\n",
    "bof = 2\n",
    "rien = 1\n",
    "\n",
    "poids = {\n",
    " 'popularity' : colonne_cle,\n",
    " 'year_exact' : important,\n",
    " 'Decennie' : colonne_cle,\n",
    " 'runtime_exact' : rien,\n",
    " 'vote_exact' : important,\n",
    " 'arrondi_vote_exact' : colonne_cle,\n",
    "# 'vote_count_mean' : important,\n",
    " 'prod_US' : important,\n",
    " 'prod_FR' : important\n",
    "}\n",
    "\n",
    "for element in df.select_dtypes(include = 'number').columns:\n",
    "    if \"production_companies_name\" in element:\n",
    "        poids.update({element : important})\n",
    "    elif \"acteur_{\" in element:\n",
    "        poids.update({element : tres_important})\n",
    "    elif \"realisateurs_\" in element:\n",
    "        poids.update({element : tres_important})\n",
    "    elif \"genre_\" in element:\n",
    "        poids.update({element : colonne_cle})\n",
    "    # else:\n",
    "    #      poids.update({element : rien})\n",
    "\n",
    "\n",
    "\n",
    "for element in poids_list.columns:\n",
    "    if element not in poids.keys():\n",
    "        poids.update({element : rien})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RECHERCHE DU TITRE\n",
    "\n",
    "df_recherche = df.copy()\n",
    "df_recherche['title_out_KNN'] = df_recherche['title_out_KNN'].apply(lambda x : x.lower())\n",
    "recherche = 'avatar 2'\n",
    "recherche2 = recherche.lower().split(\" \")\n",
    "\n",
    "for element in recherche2:\n",
    "    df_recherche2 = df_recherche[df_recherche['title_out_KNN'].str.contains(element)]\n",
    "    df_recherche = df_recherche2\n",
    "\n",
    "film_id = df_recherche2['film_id_out_KNN'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # RECHERCHE DU REALISATEURS\n",
    "\n",
    "# df_realisateurs_recherche = pd.DataFrame(df_realisateurs[df_realisateurs['film_id_out_KNN'].str.contains(film_id) == True]['primaryName']).drop_duplicates()\n",
    "# df_realisateurs_recherche"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BASES\n",
    "\n",
    "X = df[caracteristiques]\n",
    "\n",
    "df_a_predire = df[df['film_id_out_KNN'] == film_id]\n",
    "search = df_a_predire['title_out_KNN'].iloc[0]\n",
    "# df_a_predire = df_a_predire.drop('title_len_out_KNN', axis = 1)\n",
    "df_a_predire = df_a_predire[caracteristiques]\n",
    "\n",
    "\n",
    "k_range = (3,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FONCTION 1\n",
    "\n",
    "X_encoded, SN = encodage_X(X, 'standard', poids)\n",
    "\n",
    "# # FONCTION 2\n",
    "\n",
    "avg_distances, silhouette_scores = evaluate_k(X_encoded, k_range)\n",
    "\n",
    "# # FONCTION 3\n",
    "\n",
    "df_final = encodage_predict(df_a_predire, SN, poids, X_encoded)\n",
    "\n",
    "# # FONCTION 4\n",
    "\n",
    "# On choisit k\n",
    "k=8\n",
    "\n",
    "model = NearestNeighbors(n_neighbors=k, metric='euclidean')\n",
    "model.fit(X_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input X contains NaN.\nNearestNeighbors does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[76], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m caracteristiques\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfilm_id_out_KNN\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m resultat \u001b[38;5;241m=\u001b[39m pokemons_similaires(df[caracteristiques], film_id, model, SN, poids, X_encoded, df)\n\u001b[1;32m      3\u001b[0m choix \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(df[df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtitle_out_KNN\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m search])\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# # choix2 = choix.drop(columns = choix.columns[22:])\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# # resultat2 = resultat.drop(columns = resultat.columns[22:])\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[67], line 109\u001b[0m, in \u001b[0;36mpokemons_similaires\u001b[0;34m(X, film_id, model, SN, poids, X_encoded, df)\u001b[0m\n\u001b[1;32m    105\u001b[0m caract_pokemon \u001b[38;5;241m=\u001b[39m X[X[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfilm_id_out_KNN\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m film_id]\n\u001b[1;32m    107\u001b[0m caract_pokemon_encoded \u001b[38;5;241m=\u001b[39m encodage_predict(caract_pokemon, SN, poids, X_encoded)\n\u001b[0;32m--> 109\u001b[0m distances, indices \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mkneighbors(caract_pokemon_encoded)\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m df\u001b[38;5;241m.\u001b[39miloc[indices[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/neighbors/_base.py:826\u001b[0m, in \u001b[0;36mKNeighborsMixin.kneighbors\u001b[0;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[1;32m    824\u001b[0m         X \u001b[38;5;241m=\u001b[39m _check_precomputed(X)\n\u001b[1;32m    825\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 826\u001b[0m         X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(X, accept_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m, reset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, order\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    828\u001b[0m n_samples_fit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_samples_fit_\n\u001b[1;32m    829\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_neighbors \u001b[38;5;241m>\u001b[39m n_samples_fit:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py:633\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    631\u001b[0m         out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[0;32m--> 633\u001b[0m     out \u001b[38;5;241m=\u001b[39m check_array(X, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[1;32m    634\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n\u001b[1;32m    635\u001b[0m     out \u001b[38;5;241m=\u001b[39m _check_y(y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/validation.py:1049\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m   1043\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1044\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expected <= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1045\u001b[0m         \u001b[38;5;241m%\u001b[39m (array\u001b[38;5;241m.\u001b[39mndim, estimator_name)\n\u001b[1;32m   1046\u001b[0m     )\n\u001b[1;32m   1048\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m force_all_finite:\n\u001b[0;32m-> 1049\u001b[0m     _assert_all_finite(\n\u001b[1;32m   1050\u001b[0m         array,\n\u001b[1;32m   1051\u001b[0m         input_name\u001b[38;5;241m=\u001b[39minput_name,\n\u001b[1;32m   1052\u001b[0m         estimator_name\u001b[38;5;241m=\u001b[39mestimator_name,\n\u001b[1;32m   1053\u001b[0m         allow_nan\u001b[38;5;241m=\u001b[39mforce_all_finite \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow-nan\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1054\u001b[0m     )\n\u001b[1;32m   1056\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copy:\n\u001b[1;32m   1057\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_numpy_namespace(xp):\n\u001b[1;32m   1058\u001b[0m         \u001b[38;5;66;03m# only make a copy if `array` and `array_orig` may share memory`\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/validation.py:126\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m first_pass_isfinite:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m--> 126\u001b[0m _assert_all_finite_element_wise(\n\u001b[1;32m    127\u001b[0m     X,\n\u001b[1;32m    128\u001b[0m     xp\u001b[38;5;241m=\u001b[39mxp,\n\u001b[1;32m    129\u001b[0m     allow_nan\u001b[38;5;241m=\u001b[39mallow_nan,\n\u001b[1;32m    130\u001b[0m     msg_dtype\u001b[38;5;241m=\u001b[39mmsg_dtype,\n\u001b[1;32m    131\u001b[0m     estimator_name\u001b[38;5;241m=\u001b[39mestimator_name,\n\u001b[1;32m    132\u001b[0m     input_name\u001b[38;5;241m=\u001b[39minput_name,\n\u001b[1;32m    133\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/validation.py:175\u001b[0m, in \u001b[0;36m_assert_all_finite_element_wise\u001b[0;34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m estimator_name \u001b[38;5;129;01mand\u001b[39;00m input_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m has_nan_error:\n\u001b[1;32m    159\u001b[0m     \u001b[38;5;66;03m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[1;32m    160\u001b[0m     \u001b[38;5;66;03m# scikit-learn.\u001b[39;00m\n\u001b[1;32m    161\u001b[0m     msg_err \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    162\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not accept missing values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    163\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#estimators-that-handle-nan-values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    174\u001b[0m     )\n\u001b[0;32m--> 175\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[0;31mValueError\u001b[0m: Input X contains NaN.\nNearestNeighbors does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values"
     ]
    }
   ],
   "source": [
    "caracteristiques.append('film_id_out_KNN')\n",
    "resultat = pokemons_similaires(df[caracteristiques], film_id, model, SN, poids, X_encoded, df)\n",
    "choix = pd.DataFrame(df[df['title_out_KNN'] == search])\n",
    "\n",
    "# # choix2 = choix.drop(columns = choix.columns[22:])\n",
    "# # resultat2 = resultat.drop(columns = resultat.columns[22:])\n",
    "\n",
    "final = pd.concat([choix, resultat])\n",
    "final = final.drop(0)\n",
    "\n",
    "caracteristiques.remove('film_id_out_KNN')\n",
    "\n",
    "final.transpose()\n",
    "final['title_out_KNN']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ACTEURS ET REALISATEURS DU FILM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "liste_acteurs = []\n",
    "for element in df_a_predire.columns:\n",
    "    if 'acteur' in element and df_a_predire[element].iloc[0] == 1:\n",
    "        liste_acteurs.append(element[7:])\n",
    "        \n",
    "liste_realisateurs = []\n",
    "for element in df_a_predire.columns:\n",
    "    if 'realisateur' in element and df_a_predire[element].iloc[0] == 1:\n",
    "        liste_realisateurs.append(element[13:])\n",
    "\n",
    "liste_production_companies_name = []\n",
    "for element in df_a_predire.columns:\n",
    "    if 'production_companies_name' in element and df_a_predire[element].iloc[0] == 1:\n",
    "        liste_production_companies_name.append(element[26:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_acteurs = df_acteurs[~(df_acteurs['film_id_out_KNN'] == film_id)]\n",
    "df_acteurs['acteur_out_KNN'] = df_acteurs['acteur_out_KNN'].astype(str)\n",
    "df_acteurs['acteur_out_KNN'] = df_acteurs['acteur_out_KNN'].apply(lambda x : str(x))\n",
    "df_acteurs = df_acteurs.sort_values(by = 'vote_exact', ascending = False)\n",
    "\n",
    "dico_acteur = {}\n",
    "\n",
    "for element in liste_acteurs:\n",
    "    dico_acteur.update({df_acteurs[df_acteurs['acteur_out_KNN'].str.contains(element.lower())].sort_values(by = 'vote_exact', ascending = False).head()['vote_exact'].mean() : element})\n",
    "\n",
    "sorted_dico_acteur = dict(sorted(dico_acteur.items(), reverse = True))\n",
    "\n",
    "for element in sorted_dico_acteur.values():\n",
    "    element = element.lower()\n",
    "    display(df_acteurs[df_acteurs['acteur_out_KNN'].str.contains(element)].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_realisateurs = df_realisateurs[~(df_realisateurs['film_id_out_KNN'] == film_id)]\n",
    "df_realisateurs['realisateurs_out_KNN'] = df_realisateurs['realisateurs_out_KNN'].astype(str)\n",
    "df_realisateurs['realisateurs_out_KNN'] = df_realisateurs['realisateurs_out_KNN'].apply(lambda x : str(x))\n",
    "df_realisateurs = df_realisateurs.sort_values(by = 'vote_exact', ascending = False)\n",
    "\n",
    "dico_realisateur = {}\n",
    "\n",
    "for element in liste_realisateurs:\n",
    "    dico_realisateur.update({df_realisateurs[df_realisateurs['realisateurs_out_KNN'].str.contains(element.lower())].sort_values(by = 'vote_exact', ascending = False).head()['vote_exact'].mean() : element})\n",
    "\n",
    "sorted_dico_realisateur = dict(sorted(dico_realisateur.items(), reverse = True))\n",
    "\n",
    "for element in sorted_dico_realisateur.values():\n",
    "    element = element.lower()\n",
    "    display(df_realisateurs[df_realisateurs['realisateurs_out_KNN'].str.contains(element)].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>production_companies_name_out_KNN</th>\n",
       "      <th>genre_out_KNN</th>\n",
       "      <th>title_out_KNN</th>\n",
       "      <th>film_id_out_KNN</th>\n",
       "      <th>arrondi_vote_exact</th>\n",
       "      <th>popularity</th>\n",
       "      <th>year_exact</th>\n",
       "      <th>Decennie</th>\n",
       "      <th>runtime_exact</th>\n",
       "      <th>vote_exact</th>\n",
       "      <th>...</th>\n",
       "      <th>production_companies_name_bernsbrothersproductions</th>\n",
       "      <th>production_companies_name_edfriendlyproductions</th>\n",
       "      <th>production_companies_name_sktelecom</th>\n",
       "      <th>production_companies_name_gruppobema</th>\n",
       "      <th>production_companies_name_lefooleinc.</th>\n",
       "      <th>production_companies_name_zuludawnnv</th>\n",
       "      <th>production_companies_name_filmel</th>\n",
       "      <th>production_companies_name_l.a.reidmedia</th>\n",
       "      <th>production_companies_name_apertedevue</th>\n",
       "      <th>production_companies_name_filmgalerie451</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6532</th>\n",
       "      <td>['marvelstudios']</td>\n",
       "      <td>['sciencefiction', 'adventure', 'drama', 'acti...</td>\n",
       "      <td>Avengers:Phasefinale</td>\n",
       "      <td>tt4154796</td>\n",
       "      <td>8.0</td>\n",
       "      <td>101.337</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>8.35</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7279</th>\n",
       "      <td>['marvelstudios']</td>\n",
       "      <td>['sci-fi', 'sciencefiction', 'adventure', 'act...</td>\n",
       "      <td>Avengers:laguerredelinfini</td>\n",
       "      <td>tt4154756</td>\n",
       "      <td>8.0</td>\n",
       "      <td>205.036</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>8.35</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6558</th>\n",
       "      <td>['marvelstudios', 'kevinfeigeproductions']</td>\n",
       "      <td>['sciencefiction', 'adventure', 'comedy', 'act...</td>\n",
       "      <td>LesgardiensdelagalaxieVol.3</td>\n",
       "      <td>tt6791350</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2520.308</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>8.10</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6429</th>\n",
       "      <td>['marvelstudios', 'pascalpictures', 'columbiap...</td>\n",
       "      <td>['sciencefiction', 'fantasy', 'adventure', 'ac...</td>\n",
       "      <td>Spider-Man:SansRetour</td>\n",
       "      <td>tt10872600</td>\n",
       "      <td>8.0</td>\n",
       "      <td>262.366</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>8.10</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6566</th>\n",
       "      <td>['marvelstudios']</td>\n",
       "      <td>['sciencefiction', 'adventure', 'comedy', 'act...</td>\n",
       "      <td>Lesgardiensdelagalaxie</td>\n",
       "      <td>tt2015381</td>\n",
       "      <td>8.0</td>\n",
       "      <td>255.418</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>7.95</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 304 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      production_companies_name_out_KNN  \\\n",
       "6532                                  ['marvelstudios']   \n",
       "7279                                  ['marvelstudios']   \n",
       "6558         ['marvelstudios', 'kevinfeigeproductions']   \n",
       "6429  ['marvelstudios', 'pascalpictures', 'columbiap...   \n",
       "6566                                  ['marvelstudios']   \n",
       "\n",
       "                                          genre_out_KNN  \\\n",
       "6532  ['sciencefiction', 'adventure', 'drama', 'acti...   \n",
       "7279  ['sci-fi', 'sciencefiction', 'adventure', 'act...   \n",
       "6558  ['sciencefiction', 'adventure', 'comedy', 'act...   \n",
       "6429  ['sciencefiction', 'fantasy', 'adventure', 'ac...   \n",
       "6566  ['sciencefiction', 'adventure', 'comedy', 'act...   \n",
       "\n",
       "                    title_out_KNN film_id_out_KNN  arrondi_vote_exact  \\\n",
       "6532         Avengers:Phasefinale       tt4154796                 8.0   \n",
       "7279   Avengers:laguerredelinfini       tt4154756                 8.0   \n",
       "6558  LesgardiensdelagalaxieVol.3       tt6791350                 8.0   \n",
       "6429        Spider-Man:SansRetour      tt10872600                 8.0   \n",
       "6566       Lesgardiensdelagalaxie       tt2015381                 8.0   \n",
       "\n",
       "      popularity  year_exact  Decennie  runtime_exact  vote_exact  ...  \\\n",
       "6532     101.337      2019.0    2010.0          181.0        8.35  ...   \n",
       "7279     205.036      2018.0    2010.0          149.0        8.35  ...   \n",
       "6558    2520.308      2023.0    2020.0          150.0        8.10  ...   \n",
       "6429     262.366      2021.0    2020.0          148.0        8.10  ...   \n",
       "6566     255.418      2014.0    2010.0          121.0        7.95  ...   \n",
       "\n",
       "      production_companies_name_bernsbrothersproductions  \\\n",
       "6532                                                  0    \n",
       "7279                                                  0    \n",
       "6558                                                  0    \n",
       "6429                                                  0    \n",
       "6566                                                  0    \n",
       "\n",
       "      production_companies_name_edfriendlyproductions  \\\n",
       "6532                                                0   \n",
       "7279                                                0   \n",
       "6558                                                0   \n",
       "6429                                                0   \n",
       "6566                                                0   \n",
       "\n",
       "     production_companies_name_sktelecom production_companies_name_gruppobema  \\\n",
       "6532                                   0                                    0   \n",
       "7279                                   0                                    0   \n",
       "6558                                   0                                    0   \n",
       "6429                                   0                                    0   \n",
       "6566                                   0                                    0   \n",
       "\n",
       "     production_companies_name_lefooleinc.  \\\n",
       "6532                                     0   \n",
       "7279                                     0   \n",
       "6558                                     0   \n",
       "6429                                     0   \n",
       "6566                                     0   \n",
       "\n",
       "     production_companies_name_zuludawnnv production_companies_name_filmel  \\\n",
       "6532                                    0                                0   \n",
       "7279                                    0                                0   \n",
       "6558                                    0                                0   \n",
       "6429                                    0                                0   \n",
       "6566                                    0                                0   \n",
       "\n",
       "     production_companies_name_l.a.reidmedia  \\\n",
       "6532                                       0   \n",
       "7279                                       0   \n",
       "6558                                       0   \n",
       "6429                                       0   \n",
       "6566                                       0   \n",
       "\n",
       "     production_companies_name_apertedevue  \\\n",
       "6532                                     0   \n",
       "7279                                     0   \n",
       "6558                                     0   \n",
       "6429                                     0   \n",
       "6566                                     0   \n",
       "\n",
       "     production_companies_name_filmgalerie451  \n",
       "6532                                        0  \n",
       "7279                                        0  \n",
       "6558                                        0  \n",
       "6429                                        0  \n",
       "6566                                        0  \n",
       "\n",
       "[5 rows x 304 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_production = df_production[~(df_production['film_id_out_KNN'] == film_id)]\n",
    "df_production['production_companies_name_out_KNN'] = df_production['production_companies_name_out_KNN'].astype(str)\n",
    "df_production['production_companies_name_out_KNN'] = df_production['production_companies_name_out_KNN'].apply(lambda x : str(x))\n",
    "df_production = df_production.sort_values(by = 'vote_exact', ascending = False)\n",
    "\n",
    "dico_production = {}\n",
    "\n",
    "for element in liste_production_companies_name:\n",
    "    dico_production.update({df_production[df_production['production_companies_name_out_KNN'].str.contains(element.lower())].sort_values(by = 'vote_exact', ascending = False).head()['vote_exact'].mean() : element})\n",
    "\n",
    "sorted_dico_production = dict(sorted(dico_production.items(), reverse = True))\n",
    "\n",
    "for element in sorted_dico_production.values():\n",
    "    element = element.lower()\n",
    "    display(df_production[df_production['production_companies_name_out_KNN'].str.contains(element)].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définition de la plage de k à tester\n",
    "\n",
    "k_range = range(1,30)\n",
    "\n",
    "# Évaluation des différentes valeurs de k\n",
    "avg_distances, silhouette_scores = evaluate_k(X_encoded, k_range)\n",
    "\n",
    "# Création d'une visualisation pour aider à choisir k\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Premier graphique : Distance moyenne aux voisins\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(k_range, avg_distances, 'bo-')\n",
    "plt.xlabel('Nombre de voisins (k)')\n",
    "plt.ylabel('Distance moyenne aux voisins')\n",
    "plt.title('Distance moyenne en fonction de k')\n",
    "plt.grid(True)\n",
    "\n",
    "# Second graphique : Score de silhouette\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(k_range[1:], silhouette_scores[1:], 'ro-')  # On commence à k=2\n",
    "plt.xlabel('Nombre de voisins (k)')\n",
    "plt.ylabel('Score de silhouette')\n",
    "plt.title('Score de silhouette en fonction de k')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EXPORTER MODEL\n",
    "\n",
    "import pickle\n",
    "\n",
    "# Sauvegarder le modèle\n",
    "with open('mon_modele.pkl', 'wb') as f:\n",
    "    pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTER MODEL\n",
    "\n",
    "import pickle\n",
    "\n",
    "# Charger le modèle\n",
    "with open('mon_modele.pkl', 'rb') as f: #là vous mettez l'emplacement et le nom de votre fichier pkl\n",
    "    model_charge = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(df_films.drop('title_out_KNN', axis=1), df_films['title_out_KNN'], test_size=0.75)\n",
    "\n",
    "# model.fit(X_train, y_train)\n",
    "\n",
    "# y_pred = model.predict(X_test)\n",
    "\n",
    "# accuracy = accuracy_score(y_test, y_pred)\n",
    "# print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# param_grid = {\"n_neighbors\": range(20)}\n",
    "\n",
    "# # Perform grid search with cross-validation\n",
    "# gscv = GridSearchCV(model, param_grid, cv=5)\n",
    "# gscv.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# print(\"Best params:\", gscv.best_params_)\n",
    "# print(\"Best cross-validation score:\", gscv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_films = df.copy()\n",
    "\n",
    "# df_films['production_companies_name2'] = df_films['production_companies_name'].apply(lambda x: x.replace(\"[\", '').replace(\"]\", '').replace(\"'\", ''))\n",
    "\n",
    "# df_films['production_companies_name3'] = df_films['production_companies_name2'].apply(lambda x : x.split(','))\n",
    "\n",
    "# tous_les_genres = set()\n",
    "# tous_les_genres2 = set()\n",
    "\n",
    "# for element in df_films['production_companies_name3']:\n",
    "#   tous_les_genres.update(element)\n",
    "\n",
    "# tous_les_genres_list = list(tous_les_genres)\n",
    "\n",
    "# tous_les_genres_list.remove(\"\")\n",
    "\n",
    "# for n in range(len(tous_les_genres_list)):\n",
    "#   tous_les_genres_list[n] = tous_les_genres_list[n].replace(\" \",\"\")\n",
    "\n",
    "# tous_les_genres2_list = list(tous_les_genres2)\n",
    "# tous_les_genres2_list.remove(\"\")\n",
    "\n",
    "# df_films['production_companies_name4'] = df_films['production_companies_name'].apply(lambda x: x.replace(\" \", ''))\n",
    "\n",
    "# new_dict = {}\n",
    "\n",
    "# for element in tous_les_genres_list:\n",
    "#     if len(df_films[df_films['production_companies_name2'].str.contains(element) == True]) >= 500:\n",
    "#       new_dict.update({element : len(df_films[df_films['production_companies_name2'].str.contains(element) == True])})\n",
    "\n",
    "# new_dict_sorted = dict(sorted(new_dict.items(), key=lambda x:x[1]))\n",
    "\n",
    "# for genre in new_dict_sorted.keys():\n",
    "#   df_films[f'production_companies_name_{genre}'] = df_films['production_companies_name4'].apply(lambda x: genre in x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_LN = df[df['vote_count_mean'] != 0].drop(['adult', 'production_countries', 'status', 'tagline', 'production_companies_name', 'production_companies_country', 'titleType', 'region', 'Decennie', 'genre', 'final_language', 'popularity', 'year_exact', 'runtime_exact', 'vote_exact', 'arrondi_vote_exact', 'vote_count_mean'], axis = 1)\n",
    "# df_LN_drop_NA = df_LN.dropna()\n",
    "# X = df_LN_drop_NA\n",
    "# y = pd.DataFrame(df_LN_drop_NA)\n",
    "\n",
    "# def encodage_X(X, type='standard'):\n",
    "#   X_num = X.select_dtypes('number')\n",
    "#   X_cat = X.select_dtypes(['object', 'category', 'string'])\n",
    "#   # Comme ça les dates, on n'y touche pas\n",
    "\n",
    "#   if type == 'standard':\n",
    "#     from sklearn.preprocessing import StandardScaler\n",
    "#     SN = StandardScaler()\n",
    "#     X_num_SN = pd.DataFrame(SN.fit_transform(X_num), columns=X_num.columns)\n",
    "\n",
    "#   else:\n",
    "#     from sklearn.preprocessing import MinMaxScaler\n",
    "#     SN = MinMaxScaler()\n",
    "#     X_num_SN = pd.DataFrame(SN.fit_transform(X_num), columns=X_num.columns)\n",
    "\n",
    "#   X_cat_dummies = pd.get_dummies(X_cat)\n",
    "#   X_encoded = pd.concat([X_num_SN.reset_index(), X_cat_dummies.reset_index()], axis=1)\n",
    "\n",
    "#   return X_encoded, SN\n",
    "\n",
    "# X_encoded, SN = encodage_X(X)\n",
    "\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, train_size=0.8)\n",
    "\n",
    "# from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# modele = LinearRegression()\n",
    "\n",
    "# modele.fit(X_train, y_train)\n",
    "\n",
    "# print(f\"Score d'entrainement {modele.score(X_train, y_train)}\")\n",
    "# print(f\"Score de test {modele.score(X_test, y_test)}\")\n",
    "\n",
    "# df_a_predire = df_test[df_test['vote_count_mean'] == 0].drop(['isOriginalTitle', 'ordering', 'film_id', 'id', 'revenue', 'budget', 'backdrop_path', 'homepage', 'overview', 'poster_path', 'status', 'tagline', 'video', 'titleType', 'types', 'attributes'], axis = 1)\n",
    "# df_a_predire = df_a_predire.drap('vote_count_mean', axis = 1)\n",
    "# df_quelonveutpredire = df_a_predire.dropna()\n",
    "\n",
    "# def encodage_predict(df_a_predire):\n",
    "#   X_num = df_a_predire.select_dtypes('number')\n",
    "#   X_cat = df_a_predire.select_dtypes(['object', 'category', 'string'])\n",
    "\n",
    "#   X_num_SN = pd.DataFrame(SN.transform(X_num), columns=X_num.columns).reset_index(drop=True)\n",
    "\n",
    "#   X_cat_dummies = pd.get_dummies(X_cat).reset_index(drop=True)\n",
    "#   X_encoded_predire = pd.concat([X_num_SN.reset_index(), X_cat_dummies.reset_index()], axis=1)\n",
    "\n",
    "#   df_predict = X_encoded_predire\n",
    "\n",
    "#   # DataFrame vide qui a les mêmes colonnes que X_encoded\n",
    "#   df_final = pd.DataFrame(columns=X_encoded.columns)\n",
    "\n",
    "#   # On veut que le DataFrame ait le même nombre de lignes que df_predict\n",
    "#   df_final = df_final.reindex(index=df_predict.index)\n",
    "#   # On met tous les NaN à False\n",
    "#   df_final = df_final.fillna(False)\n",
    "\n",
    "#   # On parcourt chaque colonne de df_predict\n",
    "#   # Si la colonne est présente dans X_encoded alors on la garde\n",
    "#   # Sinon, on la met à False\n",
    "#   for column in df_predict.columns:\n",
    "#     if column in X_encoded.columns:\n",
    "#       df_final[column] = df_predict[column]\n",
    "\n",
    "#   return df_final\n",
    "\n",
    "# df_pour_prediction = encodage_predict(df_quelonveutpredire)\n",
    "\n",
    "# df_quelonveutpredire['prediction'] = modele.predict(df_pour_prediction)\n",
    "# df_quelonveutpredire\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
